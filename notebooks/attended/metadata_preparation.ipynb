{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8bb363b",
   "metadata": {},
   "source": [
    "# Preparing metadata for archiving ApRES data from teh centerline of thwaites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b9f0de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1b5cbd",
   "metadata": {},
   "source": [
    "## Define the folder where archived data are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16efae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "archived_data_path = '../../../../../../data/thwaites_apres/archiving'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04392486",
   "metadata": {},
   "source": [
    "## Confirm that the waypoints in the metadata are the same as the directories containing the data\n",
    "For the centerline attended surveys, the .dat files are each supposed to be in a directory corresponding to their waypoint name. Below we check that this these directory names are all included in the metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "359491bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 232 waypoint 2022-2023 directories\n",
      "there are 95 waypoint 2023-2024 directories\n"
     ]
    }
   ],
   "source": [
    "# List contents of the directory and filter for just directories\n",
    "attended_22_23 = [ f.name for f in os.scandir(archived_data_path + '/attended/centerline/single/2022-2023') if f.is_dir() ]\n",
    "attended_23_24 = [ f.name for f in os.scandir(archived_data_path + '/attended/centerline/single/2023-2024') if f.is_dir() ]\n",
    "print(f\"there are {len(attended_22_23)} waypoint 2022-2023 directories\")\n",
    "print(f\"there are {len(attended_23_24)} waypoint 2023-2024 directories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a7287d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata for each year and convert to strings\n",
    "md_22_23 = pd.read_excel(archived_data_path + '/attended/centerline/single/2022-2023/metadata_notes_22-23.xlsx')\n",
    "md_23_24 = pd.read_excel(archived_data_path + '/attended/centerline/single/2023-2024/metadata_notes_23-24.xlsx')\n",
    "md_waypoints_22_23 = md_22_23.waypoint\n",
    "md_waypoints_23_24 = md_23_24.waypoint\n",
    "md_waypoints_22_23 = [str(x) for x in md_waypoints_22_23]\n",
    "md_waypoints_23_24 = [str(x) for x in md_waypoints_23_24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea958b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check that all the folder names are contained in the metadata. \n",
    "print(all([x in md_waypoints_22_23 for x in attended_22_23]))\n",
    "print(all([x in md_waypoints_23_24 for x in attended_23_24]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5c4f0",
   "metadata": {},
   "source": [
    "## Check that the centerline polarimetric folder names are in the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "833997a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 43 waypoint 2022-2023 directories\n",
      "there are 4 waypoint 2023-2024 directories\n"
     ]
    }
   ],
   "source": [
    "attended_22_23_polar = [ f.name for f in os.scandir(archived_data_path + '/attended/centerline/polarimetric/2022-2023') if f.is_dir() ]\n",
    "attended_23_24_polar = [ f.name for f in os.scandir(archived_data_path + '/attended/centerline/polarimetric/2023-2024') if f.is_dir() ]\n",
    "print(f\"there are {len(attended_22_23_polar)} waypoint 2022-2023 directories\")\n",
    "print(f\"there are {len(attended_23_24_polar)} waypoint 2023-2024 directories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a24cc9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(all([x in md_waypoints_22_23 for x in attended_22_23_polar]))\n",
    "print(all([x in md_waypoints_23_24 for x in attended_23_24_polar]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06f00ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: G6-29-05\n",
      "True: G6-39-05\n",
      "True: G6-19-05\n",
      "True: G8-05-264\n",
      "True: G6-09-05\n",
      "True: G9-041\n",
      "True: G10-09-219\n",
      "True: G9-15-234\n",
      "True: G8-15-254\n",
      "True: G9-031\n",
      "True: G5-39-05\n",
      "True: G10-04-224\n",
      "True: G5-29-05\n",
      "True: G5-09-05\n",
      "True: G5-19-05\n",
      "True: G3-39-05\n",
      "True: G7-28-05\n",
      "True: G7-38-05\n",
      "True: G9-05-244\n",
      "True: G3-29-05\n",
      "True: G3-09-05\n",
      "True: G7-18-05\n",
      "True: G7-08-05\n",
      "True: G3-19-05\n",
      "True: G8-10-259\n",
      "True: G8-20-249\n",
      "True: G9-10-239\n",
      "True: G2-10-05\n",
      "True: G9-20-229\n",
      "True: G2-30-05\n",
      "True: G4-40-05\n",
      "True: G2-20-05\n",
      "True: G4-10-05\n",
      "True: G4-30-05\n",
      "True: G4-20-05\n",
      "True: G10-032\n",
      "True: G2-40-05\n",
      "True: G1-41-05\n",
      "True: G9-061\n",
      "True: G9-051\n",
      "True: G10-042\n",
      "True: G1-21-05\n",
      "True: G1-31-05\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(([x in md_waypoints_22_23  for x in attended_22_23_polar]),attended_22_23_polar):\n",
    "    print(f\"{x}: {y}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b0cd0e",
   "metadata": {},
   "source": [
    "## Note on naming conventions and changes made to metadata and file names. \n",
    "As described in a file supplied by Elizabeth Case in the original collection of files sent to Jonny Kingslake (/Users/jkingslake/Documents/data/thwaites_apres/original/2022-2023/Polarmetric/NamingConvention.md), the naming convection of some sites have waypoint number at at the end of their name, typically are 250. Within the waypoint name which include this number, there were difference in how they are referred to between the metadata, the folder names for the single measurements, and the folder names for the polarimetric measurements. \n",
    "\n",
    "- The metadata originally just had either the box number and the waypoint number,  e.g., G8-249 or just the  the waypoint number, e.g, 248. \n",
    "- The folder names for the single measurements originally had the box number, the waypoint number, and an additional number (described in NamingConvention.md), e.g., G9-01-248\n",
    "- The folder names for the polarimetirc data had the box number and the the waypoint number,  e.g., G8-249.\n",
    "\n",
    "In the archived versions I have changed the waypoint names in the metadata and in the folder names of the polarimetric data to be the same as the folder names from teh single data, e.g., G9-01-248 wherever possible. In cases where a polarimetric waypoint is not also in the single-measurement waypoints, I have changed the metadata to be the same as the polarimetric folder names. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e2c53e",
   "metadata": {},
   "source": [
    "# Create a hybrid position record\n",
    "There are three sources of waypoint positions:\n",
    "1. The 22-23 metadata (source 1)\n",
    "2. The 23-24 metadata, but it is noted that this is from the previous season (source 2)\n",
    "3. The 23-24 metadata, recorded by the operators in 23-24 (source 3)\n",
    "Note that in some cases waypoints are listed more than once with the same or different positions. \n",
    "\n",
    "The cell below combines these using the following logic:\n",
    "For each waypoint we look first and source 1, then source 2, then finally source 3/ \n",
    "1. If any of the locations listed for a waypoint in source 1 has longitude, latitude and elevation present, we use them. If no we move onto step 2.\n",
    "2. If source 2 has an entry for this waypoint we move on to step 3 (if not we give up and put in NaNs for the position).\n",
    "3. If any of the locations listed for a waypoint in source 2 has longitude, latitude and elevation present, we use them. If not we move onto step 4.\n",
    "4. If source 3 has an entry for this waypoint (which it will because isin the same dataframe as source 2), we move onto step 5\n",
    "5. Is any of the locations listed in source 3 has a latitude present, we use the longitude, latitude and elevations from that entry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d46c7700",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_22_23.set_index('waypoint', inplace=True)\n",
    "md_23_24.set_index('waypoint', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38ffa44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_22_23.insert(md_22_23.shape[1], 'latitude (EPSG:4326 - WGS 84) combined', np.nan)\n",
    "md_22_23.insert(md_22_23.shape[1], 'longitude (EPSG:4326 - WGS 84) combined', np.nan)\n",
    "md_22_23.insert(md_22_23.shape[1], 'elevation (EPSG:4326 - WGS 84) combined', np.nan)\n",
    "md_22_23.insert(md_22_23.shape[1], 'combined location source', np.nan)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d45a4b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position data for G1-22-05 in 2022-2023 metadata is nans\n",
      "no position data for G1-22-05 in 2023-2024 (recorded in 22-23), trying to find it in 2023-2024 (recorded in 23-24)\n",
      "using 23-24 metadata for G1-22-05 recorded in 23-24 season\n",
      "position data for G1-30-05 in 2022-2023 metadata is nans\n",
      "no position data for G1-30-05 in 2023-2024 (recorded in 22-23), trying to find it in 2023-2024 (recorded in 23-24)\n",
      "using 23-24 metadata for G1-30-05 recorded in 23-24 season\n",
      "position data for G1-28-05 in 2022-2023 metadata is nans\n",
      "no position data for G1-28-05 in 2023-2024 (recorded in 22-23), trying to find it in 2023-2024 (recorded in 23-24)\n",
      "using 23-24 metadata for G1-28-05 recorded in 23-24 season\n",
      "position data for G3-23-05 in 2022-2023 metadata is nans\n",
      "no position data for G3-23-05 in 2023-2024 (recorded in 22-23), trying to find it in 2023-2024 (recorded in 23-24)\n",
      "using 23-24 metadata for G3-23-05 recorded in 23-24 season\n",
      "position data for G7-04-05 in 2022-2023 metadata is nans\n",
      "no entry for G7-04-05 in 2023-2024 metadata\n",
      "position data for G7-34-05 in 2022-2023 metadata is nans\n",
      "no entry for G7-34-05 in 2023-2024 metadata\n",
      "position data for G8-265 in 2022-2023 metadata is nans\n",
      "no entry for G8-265 in 2023-2024 metadata\n",
      "position data for G8-07-262 in 2022-2023 metadata is nans\n",
      "no entry for G8-07-262 in 2023-2024 metadata\n",
      "position data for G8-12-257 in 2022-2023 metadata is nans\n",
      "no entry for G8-12-257 in 2023-2024 metadata\n",
      "position data for G9-22-227 in 2022-2023 metadata is nans\n",
      "no entry for G9-22-227 in 2023-2024 metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kl/3mt9f4qs1559xwy3mr60s7980000gp/T/ipykernel_67820/3203668104.py:39: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '22-23 metadata' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  md_22_23.loc[waypoint, 'combined location source'] = '22-23 metadata'\n"
     ]
    }
   ],
   "source": [
    "def remove_nan_from_list(input_list):\n",
    "    \"\"\"Remove NaN values from a list.\"\"\"\n",
    "    return [c for c in input_list.tolist() if  ~np.isnan(c)]\n",
    "\n",
    "def remove_nans_from_positions(lat, lon, elev):\n",
    "    if not isinstance(lat, float):\n",
    "        lats_noNaNs = remove_nan_from_list(lat)\n",
    "        lons_noNaNs = remove_nan_from_list(lon)\n",
    "        elevs_noNaNs = remove_nan_from_list(elev)\n",
    "    else:\n",
    "        lats_noNaNs = [lat]\n",
    "        lons_noNaNs = [lon]\n",
    "        elevs_noNaNs = [elev]\n",
    "    return lats_noNaNs, lons_noNaNs, elevs_noNaNs\n",
    "\n",
    "\n",
    "\n",
    "# combine the latitude data into one list, using values from 2022-2023 where available, but replacing any nans with values from 2023-2024 metadata when needed\n",
    "skip = False\n",
    "for waypoint in md_waypoints_22_23:\n",
    "    #print(type(waypoint))\n",
    "    try:\n",
    "        waypoint = int(waypoint)\n",
    "    except ValueError: # continue with the rest of the iteration\n",
    "        pass\n",
    "\n",
    "    lat_22_23 = md_22_23.loc[waypoint, 'latitude (EPSG:4326 - WGS 84) 22-23']\n",
    "    lon_22_23 = md_22_23.loc[waypoint, 'longitude (EPSG:4326 - WGS 84) 22-23']\n",
    "    elev_22_23 = md_22_23.loc[waypoint, 'elevation (EPSG:4326 - WGS 84) 22-23']\n",
    "    #print(lat_22_23)\n",
    "    #len(lat_22_23)\n",
    "    if  (~np.isnan(lat_22_23)).any() and (~np.isnan(lon_22_23)).any() and (~np.isnan(elev_22_23)).any():\n",
    "\n",
    "        lats_noNaNs, lons_noNaNs, elevs_noNaNs = remove_nans_from_positions(lat_22_23, lon_22_23, elev_22_23)\n",
    "        \n",
    "        md_22_23.loc[waypoint, 'latitude (EPSG:4326 - WGS 84) combined'] = lats_noNaNs[0]\n",
    "        md_22_23.loc[waypoint, 'longitude (EPSG:4326 - WGS 84) combined'] = lons_noNaNs[0]\n",
    "        md_22_23.loc[waypoint, 'elevation (EPSG:4326 - WGS 84) combined'] = elevs_noNaNs[0]\n",
    "        md_22_23.loc[waypoint, 'combined location source'] = '22-23 metadata'\n",
    "        #print(f\"using 22-23 metadata for {waypoint}\")\n",
    "    else:\n",
    "        print(f\"position data for {waypoint} in 2022-2023 metadata is nans\")\n",
    "\n",
    "        try:\n",
    "            lat_23_24_from22_23 = md_23_24.loc[waypoint, 'latitude (EPSG:4326 - WGS 84) 22-23']\n",
    "            lon_23_24_from22_23 = md_23_24.loc[waypoint, 'longitude (EPSG:4326 - WGS 84) 22-23']\n",
    "            elev_23_24_from22_23 = md_23_24.loc[waypoint, 'elevation (EPSG:4326 - WGS 84) 22-23']\n",
    "        except KeyError:\n",
    "            skip_23_24 = True\n",
    "            print(f\"no entry for {waypoint} in 2023-2024 metadata\")\n",
    "            continue\n",
    "\n",
    "        if   (~np.isnan(lat_23_24_from22_23)).any() and (~np.isnan(lon_23_24_from22_23)).any() and (~np.isnan(elev_23_24_from22_23)).any():\n",
    "                \n",
    "            lats_noNaNs, lons_noNaNs, elevs_noNaNs = remove_nans_from_positions(lat_23_24_from22_23, \n",
    "                                                                                lon_23_24_from22_23, \n",
    "                                                                                elev_23_24_from22_23)\n",
    "\n",
    "            md_22_23.loc[waypoint, 'latitude (EPSG:4326 - WGS 84) combined'] = lats_noNaNs[0]\n",
    "            md_22_23.loc[waypoint, 'longitude (EPSG:4326 - WGS 84) combined'] = lons_noNaNs[0]\n",
    "            md_22_23.loc[waypoint, 'elevation (EPSG:4326 - WGS 84) combined'] = elevs_noNaNs[0]\n",
    "            md_22_23.loc[waypoint, 'combined location source'] = '23-24 metadata, recorded in 22-23'\n",
    "            print(f\"using 23-24 metadata for {waypoint} recorded in 22-23 season\")\n",
    "        else:\n",
    "            print(f\"no position data for {waypoint} in 2023-2024 (recorded in 22-23), trying to find it in 2023-2024 (recorded in 23-24)\")\n",
    "\n",
    "\n",
    "            lat_23_24 = md_23_24.loc[waypoint, 'latitude (EPSG:4326 - WGS 84) 23-24']\n",
    "            lon_23_24 = md_23_24.loc[waypoint, 'longitude (EPSG:4326 - WGS 84) 23-24']\n",
    "            elev_23_24 = md_23_24.loc[waypoint, 'elevation (EPSG:4326 - WGS 84) 23-24']\n",
    "\n",
    "            if  (~np.isnan(lat_23_24)).any():\n",
    "                lats_noNaNs, lons_noNaNs, elevs_noNaNs = remove_nans_from_positions(lat_23_24,\n",
    "                                                                                    lon_23_24,\n",
    "                                                                                    elev_23_24)\n",
    "                \n",
    "                md_22_23.loc[waypoint, 'latitude (EPSG:4326 - WGS 84) combined'] = lats_noNaNs[0]\n",
    "                md_22_23.loc[waypoint, 'longitude (EPSG:4326 - WGS 84) combined'] = lons_noNaNs[0]\n",
    "                md_22_23.loc[waypoint, 'elevation (EPSG:4326 - WGS 84) combined'] = elevs_noNaNs[0]\n",
    "                md_22_23.loc[waypoint, 'combined location source'] = '23-24 metadata recorded in 23-24 season'\n",
    "                print(f\"using 23-24 metadata for {waypoint} recorded in 23-24 season\")\n",
    "            \n",
    "            else:\n",
    "                print(f\"no lat data found for {waypoint} \")\n",
    "\n",
    "\n",
    "\n",
    "out = md_22_23.loc[:, ['latitude (EPSG:4326 - WGS 84) combined',\n",
    "                      'longitude (EPSG:4326 - WGS 84) combined',\n",
    "                      'elevation (EPSG:4326 - WGS 84) combined',\n",
    "                      'combined location source']]\n",
    "out.index.name = 'waypoint'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2175aa2",
   "metadata": {},
   "source": [
    "### Convert to a geopandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d873af",
   "metadata": {},
   "outputs": [],
   "source": [
    "geom =gpd.points_from_xy(x=out['longitude (EPSG:4326 - WGS 84) combined'], y=out['latitude (EPSG:4326 - WGS 84) combined'])\n",
    "out = gpd.GeoDataFrame(out, geometry = geom)\n",
    "out = out.set_crs('EPSG:4326')\n",
    "out.to_crs(3031, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4142544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#    display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a68ad93",
   "metadata": {},
   "source": [
    "### Shorten the names for writing to a shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff27abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_for_shape = out.copy()\n",
    "out_for_shape.rename(columns={'latitude (EPSG:4326 - WGS 84) combined': 'lat-WGS84',\n",
    "                             'longitude (EPSG:4326 - WGS 84) combined': 'lon-WGS84',\n",
    "                             'elevation (EPSG:4326 - WGS 84) combined': 'z-WGS 84',\n",
    "                             'combined location source': 'source'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4782c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_for_shape.to_file(archived_data_path + '/attended/centerline/centerline_positions.shp', driver='ESRI Shapefile')\n",
    "out_for_shape.to_csv(archived_data_path + '/attended/centerline/centerline_positions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849cb5e",
   "metadata": {},
   "source": [
    "## Combine position data from acrossline polarimetric csvs\n",
    "The polarimetric data from the across line are stored in four directories in `/Users/jkingslake/Documents/data/thwaites_apres/archiving/attended/acrossline/polarimetric/GHOST24_Polarimetric_pRES_OZ`. In each one there is a csv containing the position of the measurement. \n",
    "\n",
    "Below we collate these into one csv and geopandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf94eed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use glob to find csvs in that dir\n",
    "acrossline_polarimetric_csvs = glob.glob(archived_data_path + '/attended/acrossline/polarimetric//PpRES_*/*.csv')\n",
    "polarimetric_acrossline_positions = pd.concat((pd.read_csv(f) for f in acrossline_polarimetric_csvs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf6cc709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PpRES_20240551_001</td>\n",
       "      <td>-76.457764</td>\n",
       "      <td>-107.389709</td>\n",
       "      <td>POINT (-1410454.662 -441731.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PpRES_20240551_003</td>\n",
       "      <td>-76.472572</td>\n",
       "      <td>-104.822354</td>\n",
       "      <td>POINT (-1427249.346 -377691.319)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PpRES_20240551_004</td>\n",
       "      <td>-76.487418</td>\n",
       "      <td>-106.977237</td>\n",
       "      <td>POINT (-1410474.93 -430612.791)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PpRES_20240551_002</td>\n",
       "      <td>-76.467489</td>\n",
       "      <td>-106.578286</td>\n",
       "      <td>POINT (-1415542.4 -421407.444)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Station   Latitude   Longitude                          geometry\n",
       "0  PpRES_20240551_001 -76.457764 -107.389709    POINT (-1410454.662 -441731.5)\n",
       "0  PpRES_20240551_003 -76.472572 -104.822354  POINT (-1427249.346 -377691.319)\n",
       "0  PpRES_20240551_004 -76.487418 -106.977237   POINT (-1410474.93 -430612.791)\n",
       "0  PpRES_20240551_002 -76.467489 -106.578286    POINT (-1415542.4 -421407.444)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to \n",
    "geom =gpd.points_from_xy(x=polarimetric_acrossline_positions['Longitude'], y=polarimetric_acrossline_positions['Latitude'])\n",
    "polarimetric_acrossline_positions = gpd.GeoDataFrame(polarimetric_acrossline_positions, geometry = geom)\n",
    "polarimetric_acrossline_positions = polarimetric_acrossline_positions.set_crs('EPSG:4326')\n",
    "polarimetric_acrossline_positions.to_crs(3031, inplace=True) \n",
    "polarimetric_acrossline_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07623a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waypoint</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PpRES_20240551_001</th>\n",
       "      <td>-76.457764</td>\n",
       "      <td>-107.389709</td>\n",
       "      <td>POINT (-1410454.662 -441731.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PpRES_20240551_003</th>\n",
       "      <td>-76.472572</td>\n",
       "      <td>-104.822354</td>\n",
       "      <td>POINT (-1427249.346 -377691.319)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PpRES_20240551_004</th>\n",
       "      <td>-76.487418</td>\n",
       "      <td>-106.977237</td>\n",
       "      <td>POINT (-1410474.93 -430612.791)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PpRES_20240551_002</th>\n",
       "      <td>-76.467489</td>\n",
       "      <td>-106.578286</td>\n",
       "      <td>POINT (-1415542.4 -421407.444)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Latitude   Longitude                          geometry\n",
       "waypoint                                                                   \n",
       "PpRES_20240551_001 -76.457764 -107.389709    POINT (-1410454.662 -441731.5)\n",
       "PpRES_20240551_003 -76.472572 -104.822354  POINT (-1427249.346 -377691.319)\n",
       "PpRES_20240551_004 -76.487418 -106.977237   POINT (-1410474.93 -430612.791)\n",
       "PpRES_20240551_002 -76.467489 -106.578286    POINT (-1415542.4 -421407.444)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarimetric_acrossline_positions = polarimetric_acrossline_positions.rename(columns={'Station': 'waypoint'})\n",
    "polarimetric_acrossline_positions.set_index('waypoint', inplace=True)\n",
    "polarimetric_acrossline_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "964c305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarimetric_acrossline_positions.to_csv(archived_data_path + '/attended/acrossline/acrossline_positions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6029fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdem_tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
